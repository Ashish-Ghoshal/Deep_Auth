{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LFW Dataset Benchmarking with Mediapipe + Facenet"
      ],
      "metadata": {
        "id": "4XPwn65q_qIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from deepface import DeepFace\n",
        "from sklearn.model_selection import train_test_split\n",
        "import psutil\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "_uTwkv2S_iDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_lfw_dataset():\n",
        "    images, labels = [], []\n",
        "    image_dir = \"C:/Dataset_all/lfw\"\n",
        "    for person_dir in os.listdir(image_dir):\n",
        "        person_path = os.path.join(image_dir, person_dir)\n",
        "        for img_name in os.listdir(person_path):\n",
        "            img_path = os.path.join(person_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (160, 160))  # Resize images for consistency\n",
        "            images.append(img)\n",
        "            labels.append(person_dir)\n",
        "    return images, labels\n",
        "\n",
        "def preprocess_image(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "\n",
        "def get_model_memory_usage(detector, embedder):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    initial_mem = process.memory_info().rss\n",
        "    _ = DeepFace.analyze(\"C:/Dataset_all/face1.jpg\", detector_backend=detector, model_name=embedder)\n",
        "    final_mem = process.memory_info().rss\n",
        "    model_size = (final_mem - initial_mem) / (1024 ** 2)\n",
        "    return model_size\n"
      ],
      "metadata": {
        "id": "fUu2M3p-_iAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3yOcO0u_gXF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "images, labels = load_lfw_dataset()\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "accuracies, times = [], []\n",
        "model_size = get_model_memory_usage(\"mediapipe\", \"Facenet\")\n",
        "\n",
        "for image, true_label in zip(X_test, y_test):\n",
        "    image = preprocess_image(image)\n",
        "    start_time = time.time()\n",
        "    prediction = DeepFace.analyze(image, detector_backend=\"mediapipe\", model_name=\"Facenet\")\n",
        "    elapsed_time = time.time() - start_time\n",
        "    times.append(elapsed_time * 1000)\n",
        "    predicted_label = prediction['identity']  # Use the actual identity prediction\n",
        "    accuracies.append(predicted_label == true_label)\n",
        "\n",
        "avg_accuracy = np.mean(accuracies) * 100\n",
        "avg_time = np.mean(times)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model Combination\": [\"Mediapipe + Facenet\"],\n",
        "    \"Dataset\": [\"LFW\"],\n",
        "    \"Accuracy\": [avg_accuracy],\n",
        "    \"Speed (ms)\": [avg_time],\n",
        "    \"Model Size (MB)\": [model_size]\n",
        "})\n",
        "\n",
        "if os.path.exists(\"results.csv\"):\n",
        "    results.to_csv(\"results.csv\", mode='a', header=False, index=False)\n",
        "else:\n",
        "    results.to_csv(\"results.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASIA-WebFace Dataset Benchmarking with MTCNN + ArcFace"
      ],
      "metadata": {
        "id": "RtKhJj6e_pTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from deepface import DeepFace\n",
        "from sklearn.model_selection import train_test_split\n",
        "import psutil\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "ubOfw9GPADOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_casia_dataset():\n",
        "    images, labels = [], []\n",
        "    image_dir = \"C:/Dataset_all/casia-webface\"\n",
        "    for person_dir in os.listdir(image_dir):\n",
        "        person_path = os.path.join(image_dir, person_dir)\n",
        "        for img_name in os.listdir(person_path):\n",
        "            img_path = os.path.join(person_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (112, 112))  # Resize images for the specific ArcFace input size\n",
        "            images.append(img)\n",
        "            labels.append(person_dir)\n",
        "    return images, labels\n",
        "\n",
        "def preprocess_image(image):\n",
        "    return cv2.equalizeHist(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))  # Grayscale and equalize histogram\n",
        "\n",
        "def get_model_memory_usage(detector, embedder):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    initial_mem = process.memory_info().rss\n",
        "    _ = DeepFace.analyze(\"C:/Dataset_all/face2.jpg\", detector_backend=detector, model_name=embedder)\n",
        "    final_mem = process.memory_info().rss\n",
        "    model_size = (final_mem - initial_mem) / (1024 ** 2)\n",
        "    return model_size"
      ],
      "metadata": {
        "id": "oQsbW5TCADGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "images, labels = load_casia_dataset()\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "accuracies, times = [], []\n",
        "model_size = get_model_memory_usage(\"mtcnn\", \"ArcFace\")\n",
        "\n",
        "for image, true_label in zip(X_test, y_test):\n",
        "    image = preprocess_image(image)\n",
        "    start_time = time.time()\n",
        "    prediction = DeepFace.analyze(image, detector_backend=\"mtcnn\", model_name=\"ArcFace\")\n",
        "    elapsed_time = time.time() - start_time\n",
        "    times.append(elapsed_time * 1000)\n",
        "    predicted_label = prediction['identity']\n",
        "    accuracies.append(predicted_label == true_label)\n",
        "\n",
        "avg_accuracy = np.mean(accuracies) * 100\n",
        "avg_time = np.mean(times)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model Combination\": [\"MTCNN + ArcFace\"],\n",
        "    \"Dataset\": [\"CASIA-WebFace\"],\n",
        "    \"Accuracy\": [avg_accuracy],\n",
        "    \"Speed (ms)\": [avg_time],\n",
        "    \"Model Size (MB)\": [model_size]\n",
        "})\n",
        "\n",
        "if os.path.exists(\"results.csv\"):\n",
        "    results.to_csv(\"results.csv\", mode='a', header=False, index=False)\n",
        "else:\n",
        "    results.to_csv(\"results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "pA0ZmWYN_00e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGGFace2 Dataset Benchmarking with Mediapipe + VGG-Face"
      ],
      "metadata": {
        "id": "sAadxtRn_41r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from deepface import DeepFace\n",
        "from sklearn.model_selection import train_test_split\n",
        "import psutil\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "0Vwfn45e_-qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_vggface2_dataset():\n",
        "    images, labels = [], []\n",
        "    image_dir = \"C:/Dataset_all/vggface2\"\n",
        "    for person_dir in os.listdir(image_dir):\n",
        "        person_path = os.path.join(image_dir, person_dir)\n",
        "        for img_name in os.listdir(person_path):\n",
        "            img_path = os.path.join(person_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (224, 224))  # Resize for VGG-Face\n",
        "            images.append(img)\n",
        "            labels.append(person_dir)\n",
        "    return images, labels\n",
        "\n",
        "def preprocess_image(image):\n",
        "    mean = np.array([129.1863, 104.7624, 93.5940])  # VGG-Face mean subtraction values\n",
        "    return image - mean  # Subtract mean from image\n",
        "\n",
        "def get_model_memory_usage(detector, embedder):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    initial_mem = process.memory_info().rss\n",
        "    _ = DeepFace.analyze(\"C:/Dataset_all/face3.jpg\", detector_backend=detector, model_name=embedder)\n",
        "    final_mem = process.memory_info().rss\n",
        "    model_size = (final_mem - initial_mem) / (1024 ** 2)\n",
        "    return model_size"
      ],
      "metadata": {
        "id": "GBzQ6HTC_-kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "images, labels = load_vggface2_dataset()\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "accuracies, times = [], []\n",
        "model_size = get_model_memory_usage(\"mediapipe\", \"VGG-Face\")\n",
        "\n",
        "for image, true_label in zip(X_test, y_test):\n",
        "    image = preprocess_image(image)\n",
        "    start_time = time.time()\n",
        "    prediction = DeepFace.analyze(image, detector_backend=\"mediapipe\", model_name=\"VGG-Face\")\n",
        "    elapsed_time = time.time() - start_time\n",
        "    times.append(elapsed_time * 1000)\n",
        "    predicted_label = prediction['identity']\n",
        "    accuracies.append(predicted_label == true_label)\n",
        "\n",
        "avg_accuracy = np.mean(accuracies) * 100\n",
        "avg_time = np.mean(times)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model Combination\": [\"Mediapipe + VGG-Face\"],\n",
        "    \"Dataset\": [\"VGGFace2\"],\n",
        "    \"Accuracy\": [avg_accuracy],\n",
        "    \"Speed (ms)\": [avg_time],\n",
        "    \"Model Size (MB)\": [model_size]\n",
        "})\n",
        "\n",
        "if os.path.exists(\"results.csv\"):\n",
        "    results.to_csv(\"results.csv\", mode='a', header=False, index=False)\n",
        "else:\n",
        "    results.to_csv(\"results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Vznq1XJF_7za"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}